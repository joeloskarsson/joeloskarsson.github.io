---
---
@article{adamov2025building,
  title={Building Machine Learning Limited Area Models: Kilometer-Scale Weather Forecasting in Realistic Settings},
  author={Adamov*, Simon and Oskarsson*, Joel and Denby, Leif and Landelius, Tomas and Hintz, Kasper and Christiansen, Simon and Schicker, Irene and Osuna, Carlos and Lindsten, Fredrik and Fuhrer, Oliver and Schemm,Sebastian},
  journal={arXiv preprint},
  year={2025},
  pdf={https://arxiv.org/abs/2504.09340},
  abstract={Machine learning is revolutionizing global weather forecasting, with models that efficiently produce highly accurate forecasts. Apart from global forecasting there is also a large value in high-resolution regional weather forecasts, focusing on accurate simulations of the atmosphere for a limited area. Initial attempts have been made to use machine learning for such limited area scenarios, but these experiments do not consider realistic forecasting settings and do not investigate the many design choices involved. We present a framework for building kilometer-scale machine learning limited area models with boundary conditions imposed through a flexible boundary forcing method. This enables boundary conditions defined either from reanalysis or operational forecast data. Our approach employs specialized graph constructions with rectangular and triangular meshes, along with multi-step rollout training strategies to improve temporal consistency. We perform systematic evaluation of different design choices, including the boundary width, graph construction and boundary forcing integration. Models are evaluated across both a Danish and a Swiss domain, two regions that exhibit different orographical characteristics. Verification is performed against both gridded analysis data and in-situ observations, including a case study for the storm Ciara in February 2020. Both models achieve skillful predictions across a wide range of variables, with our Swiss model outperforming the numerical weather prediction baseline for key surface variables. With their substantially lower computational cost, our findings demonstrate great potential for machine learning limited area models in the future of regional weather forecasting.},
  bibtex_show={true},
  preview={building_lams.png},
  code={https://github.com/joeloskarsson/neural-lam-dev/releases/tag/building-ml-lams},
  slides={slides_ml4esm_bonn_2025.pdf},
  annotation={* Equal contribution},
  selected={true},
}

@inproceedings{andrae2024continuousensembleweatherforecasting,
    title={Continuous Ensemble Weather Forecasting with Diffusion models},
    author={Martin Andrae and Tomas Landelius and Joel Oskarsson and Fredrik Lindsten},
    booktitle={International Conference on Learning Representations},
    year={2025},
    pdf={https://arxiv.org/abs/2410.05431},
    abstract={Weather forecasting has seen a shift in methods from numerical simulations to data-driven systems. While initial research in the area focused on deterministic forecasting, recent works have used diffusion models to produce skillful ensemble forecasts. These models are trained on a single forecasting step and rolled out autoregressively. However, they are computationally expensive and accumulate errors for high temporal resolution due to the many rollout steps. We address these limitations with Continuous Ensemble Forecasting, a novel and flexible method for sampling ensemble forecasts in diffusion models. The method can generate temporally consistent ensemble trajectories completely in parallel, with no autoregressive steps. Continuous Ensemble Forecasting can also be combined with autoregressive rollouts to yield forecasts at an arbitrary fine temporal resolution without sacrificing accuracy. We demonstrate that the method achieves competitive results for global weather forecasting with good probabilistic properties.},
    bibtex_show={true},
    preview = {cont_ens.png},
    code={https://github.com/martinandrae/Continuous-Ensemble-Forecasting}
}

@inproceedings{oskarsson2024probabilistic,
  title={Probabilistic Weather Forecasting with Hierarchical Graph Neural Networks},
  author={Joel Oskarsson and Tomas Landelius and Marc Peter Deisenroth and Fredrik Lindsten},
  year={2024},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {37},
  abstract={In recent years, machine learning has established itself as a powerful tool for high-resolution weather forecasting. While most current machine learning models focus on deterministic forecasts, accurately capturing the uncertainty in the chaotic weather system calls for probabilistic modeling. We propose a probabilistic weather forecasting model called Graph-EFM, combining a flexible latent-variable formulation with the successful graph-based forecasting framework. The use of a hierarchical graph construction allows for efficient sampling of spatially coherent forecasts. Requiring only a single forward pass per time step, Graph-EFM allows for fast generation of arbitrarily large ensembles. We experiment with the model on both global and limited area forecasting. Ensemble forecasts from Graph-EFM achieve equivalent or lower errors than comparable deterministic models, with the added benefit of accurately capturing forecast uncertainty.},
  bibtex_show={true},
  pdf = {https://arxiv.org/abs/2406.04759},
  code = {https://github.com/mllam/neural-lam/tree/prob_model_global},
  preview = {graph_efm.png},
  note = {Spotlight},
  selected={true},
}

@article{gopakumar2024uncertainty,
  title={Uncertainty Quantification of Pre-Trained and Fine-Tuned Surrogate Models using Conformal Prediction},
  author={Gopakumar, Vignesh and Gray, Ander and Oskarsson, Joel and Zanisi, Lorenzo and Pamela, Stanislas and Giles, Daniel and Kusner, Matt and Deisenroth, Marc Peter},
  journal={arXiv preprint},
  year={2024},
  abstract={Data-driven surrogate models have shown immense potential as quick, inexpensive approximations to complex numerical and experimental modelling tasks. However, most surrogate models characterising physical systems do not quantify their uncertainty, rendering their predictions unreliable, and needing further validation. Though Bayesian approximations offer some solace in estimating the error associated with these models, they cannot provide they cannot provide guarantees, and the quality of their inferences depends on the availability of prior information and good approximations to posteriors for complex problems. This is particularly pertinent to multi-variable or spatio-temporal problems. Our work constructs and formalises a conformal prediction framework that satisfies marginal coverage for spatio-temporal predictions in a model-agnostic manner, requiring near-zero computational costs. The paper provides an extensive empirical study of the application of the framework to ascertain valid error bars that provide guaranteed coverage across the surrogate model's domain of operation. The application scope of our work extends across a large range of spatio-temporal models, ranging from solving partial differential equations to weather forecasting. Through the applications, the paper looks at providing statistically valid error bars for deterministic models, as well as crafting guarantees to the error bars of probabilistic models. The paper concludes with a viable conformal prediction formalisation that provides guaranteed coverage of the surrogate model, regardless of model architecture, and its training regime and is unbothered by the curse of dimensionality.},
  bibtex_show={true},
  pdf = {https://arxiv.org/abs/2408.09881},
  code = {https://github.com/gitvicky/Spatio-Temporal-UQ},
  preview = {thumb_cp_surrogate_models.png}
}

@article{westny2023graph,
  journal={IEEE Transactions on Intelligent Vehicles},
  title={MTP-GO: Graph-Based Probabilistic Multi-Agent Trajectory Prediction with Neural ODEs},
  year={2023},
  author={Westny, Theodor and Oskarsson, Joel and Olofsson, Bj{\"o}rn and Frisk, Erik},
  abstract = {Enabling resilient autonomous motion planning requires robust predictions of surrounding road users' future behavior. In response to this need and the associated challenges, we introduce our model, titled MTP-GO. The model encodes the scene using temporal graph neural networks to produce the inputs to an underlying motion model. The motion model is implemented using neural ordinary differential equations where the state-transition functions are learned with the rest of the model. Multi-modal probabilistic predictions are provided by combining the concept of mixture density networks and Kalman filtering. The results illustrate the predictive capabilities of the proposed model across various data sets, outperforming several state-of-the-art methods on a number of metrics.},
  bibtex_show={true},
  pdf = {https://ieeexplore.ieee.org/abstract/document/10143287},
  code = {https://github.com/westny/mtp-go},
  preview = {thumb_round.png}
}

@INPROCEEDINGS{westny2023evaluation,
  title={Evaluation of Differentially Constrained Motion Models for Graph-Based Trajectory Prediction},
  author={Westny, Theodor and Oskarsson, Joel and Olofsson, Bj{\"o}rn and Frisk, Erik},
  booktitle={2023 IEEE Intelligent Vehicles Symposium (IV)},
  year={2023},
  abstract = {Given their flexibility and encouraging performance, deep-learning models are becoming standard for motion prediction in autonomous driving. However, with great flexibility comes a lack of interpretability and possible violations of physical constraints. Accompanying these data-driven methods with differentially-constrained motion models to provide physically feasible trajectories is a promising future direction. The foundation for this work is a previously introduced graph-neural-network-based model, MTP-GO. The neural network learns to compute the inputs to an underlying motion model to provide physically feasible trajectories. This research investigates the performance of various motion models in combination with numerical solvers for the prediction task. The study shows that simpler models, such as low-order integrator models, are preferred over more complex, e.g., kinematic models, to achieve accurate predictions. Further, the numerical solver can have a substantial impact on performance, advising against commonly used first-order methods like Euler forward. Instead, a second-order method like Heun's can greatly improve predictions.},
  bibtex_show={true},
  pdf = {https://ieeexplore.ieee.org/document/10186615},
  code = {https://github.com/westny/mtp-go},
  preview = {thumb_evaluation_diff.png},
}

@InProceedings{tgnn4i,
  title = 	 {Temporal Graph Neural Networks for Irregular Data},
  author =       {Oskarsson, Joel and Sid\'en, Per and Lindsten, Fredrik},
  booktitle = 	 {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {4515--4531},
  year = 	 {2023},
  editor = 	 {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},
  volume = 	 {206},
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
  bibtex_show={true},
  pdf = 	 {https://proceedings.mlr.press/v206/oskarsson23a/oskarsson23a.pdf},
  abstract = 	 {This paper proposes a temporal graph neural network model for forecasting of graph-structured irregularly observed time series. Our TGNN4I model is designed to handle both irregular time steps and partial observations of the graph. This is achieved by introducing a time-continuous latent state in each node, following a linear Ordinary Differential Equation (ODE) defined by the output of a Gated Recurrent Unit (GRU). The ODE has an explicit solution as a combination of exponential decay and periodic dynamics. Observations in the graph neighborhood are taken into account by integrating graph neural network layers in both the GRU state update and predictive model. The time-continuous dynamics additionally enable the model to make predictions at arbitrary time steps. We propose a loss function that leverages this and allows for training the model for forecasting over different time horizons. Experiments on simulated data and real-world data from traffic and climate modeling validate the usefulness of both the graph structure and time-continuous dynamics in settings with irregular observations.},
  code = {https://github.com/joeloskarsson/tgnn4i},
  preview = {thumb_periodic_tgnn.png},
  poster = {AISTATS_poster_tgnn4i.pdf},
  slides = {TGNN4I_AISTATS_presentation.pdf},
  video = {https://www.youtube.com/watch?v=r0mpZjUnpHA},
  selected={true},
}

@InProceedings{pmlr-v162-oskarsson22a,
  bibtex_show={true},
  title = 	 {Scalable Deep {G}aussian {M}arkov Random Fields for General Graphs},
  author =       {Oskarsson, Joel and Sid{\'e}n, Per and Lindsten, Fredrik},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {17117--17137},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/oskarsson22a/oskarsson22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/oskarsson22a.html},
  abstract = 	 {Machine learning methods on graphs have proven useful in many applications due to their ability to handle generally structured data. The framework of Gaussian Markov Random Fields (GMRFs) provides a principled way to define Gaussian models on graphs by utilizing their sparsity structure. We propose a flexible GMRF model for general graphs built on the multi-layer structure of Deep GMRFs, originally proposed for lattice graphs only. By designing a new type of layer we enable the model to scale to large graphs. The layer is constructed to allow for efficient training using variational inference and existing software frameworks for Graph Neural Networks. For a Gaussian likelihood, close to exact Bayesian inference is available for the latent field. This allows for making predictions with accompanying uncertainty estimates. The usefulness of the proposed model is verified by experiments on a number of synthetic and real world datasets, where it compares favorably to other both Bayesian and deep learning methods.},
  code = {https://github.com/joeloskarsson/graph-dgmrf},
  poster = {graph_dgmrf_poster.pdf},
  slides = {icml22_slides_graph_dgmrf.pdf},
  video = {https://icml.cc/virtual/2022/spotlight/17282},
  preview = {thumb_graph_dgmrf.png},
}

